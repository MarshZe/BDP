{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 提交作业的时候会将spark代码提交到hdfs上面，哪台服务器要执行任务就从hdfs上面下载spark代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sparkContext "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 封装了spark执行环境信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三种配置参数方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 程序内设置（优先级最高）不推荐使用，如果参数发生变化每次都需要修改代码重新打包\n",
    "conf.set(“spark.ui.port”, “14040”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 提交参数（优先级次之）推荐使用\n",
    "spark-submit \\\n",
    "--master local \\\n",
    "--conf spark.ui.port=14040 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 默认参数（优先级最低）\n",
    "conf/spark-defaults.conf\n",
    "在文件中增加一行 spark.ui.port=14040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### executor 上面可以执行多个task,每个task是一个线程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spark高级特性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 闭包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 广播变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 高效分发大对象,比如字典( map ),集合( set )等,每个 executor 一份,而不是每个 task 一份;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 广播变量不允许修改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 累加计数器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### int total = accessLogRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 类似于 MapReduce 中的 counter ,将数据从一个节点发送到其他各个节点上去"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 通常用于监控,调试,记录符合某类特征的数据数目等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 允许将 RDD 缓存到内存中或磁盘上,以便于重用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 经过的算子越多越好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 只会放到内存中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 访问外部数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 用foreachPartition操作Partition，为每个Partition创建一个数据库链接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 实例代码\n",
    "logRDD.foreachPartition(new VoidFunction<Iterator<Tuple3<String, String,Integer>>>() {public void call(Iterator<Tuple3<String, String, Integer>> integerIterator) throws\n",
    "Exception {\n",
    "val conn = createNewConnection();\n",
    "while(Iterator.hasNext()) {\n",
    "conn.send(Iterator.next());\n",
    "}\n",
    "conn.close();\n",
    "}\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### zip 两个RDD长度不一样会怎么样？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AccumulatorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 案例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
